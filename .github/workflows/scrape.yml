name: "Scrape"

on:
  # Ejecutar manualmente
  workflow_dispatch:
  # Ejecutar todos los días a las 6:00 AM UTC (1:00 AM Perú)
  schedule:
    - cron: "0 6 * * *"

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.12
      uses: actions/setup-python@v2
      with:
        python-version: "3.12"

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install typing-extensions numpy pytz python-dateutil soupsieve
        pip install selenium beautifulsoup4 pandas --no-deps

    - name: Install Chrome
      run: |
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo apt install -y ./google-chrome-stable_current_amd64.deb

    - name: Download and install matching ChromeDriver
      run: |
        CHROME_VERSION=$(google-chrome --version | cut -d ' ' -f 3 | cut -d '.' -f 1)
        DRIVER_VERSION=$(curl -sS "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_${CHROME_VERSION}")
        wget "https://chromedriver.storage.googleapis.com/${DRIVER_VERSION}/chromedriver_linux64.zip"
        unzip chromedriver_linux64.zip
        sudo mv chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver

    - name: Run scrape script
      run: python scrape.py

    - name: Commit changes to DATA folder
      run: |
        git config --global user.email "ximena.quispe.t@uni.pe"
        git config --global user.name "Ximena Quispe"
        git add DATA/
        git diff --staged --quiet || git commit -m 'New SBS entries'
        git push
