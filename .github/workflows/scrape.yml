name: "Scrape"

on:
  # Ejecutar manualmente
  workflow_dispatch:
  # Ejecutar todos los días a las 6:00 AM UTC (1:00 AM Perú)
  schedule:
    - cron: "0 6 * * *"

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.12
      uses: actions/setup-python@v2
      with:
        python-version: "3.12"

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install typing-extensions numpy pytz python-dateutil soupsieve
        pip install selenium beautifulsoup4 pandas --no-deps

    - name: Install Chrome
      run: |
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo apt install -y ./google-chrome-stable_current_amd64.deb
    - name: Install specific Chrome version (124)
      run: |
        wget https://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_124.0.6367.91-1_amd64.deb
        sudo apt install -y ./google-chrome-stable_124.0.6367.91-1_amd64.deb

    - name: Install matching ChromeDriver version (124)
      run: |
        wget https://chromedriver.storage.googleapis.com/124.0.6367.91/chromedriver_linux64.zip
        unzip chromedriver_linux64.zip
        sudo mv chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver
    
    - name: Run scrape script
      run: python scrape.py

    - name: Commit changes to DATA folder
      run: |
        git config --global user.email "ximena.quispe.t@uni.pe"
        git config --global user.name "Ximena Quispe"
        git add DATA/
        git diff --staged --quiet || git commit -m 'New SBS entries'
        git push
